{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k fold cross validation - Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is when, we have balanced datasets. means 50% Yes and 50% No. Binary Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import model_selection\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    df = pd.read_csv('advertising.csv')\n",
    "    df['kfold'] = -1\n",
    "    df = df.sample(frac = 1).reset_index(drop = True)\n",
    "    kf = model_selection.KFold(n_splits = 5)\n",
    "    for fold,(t_,v_) in enumerate(kf.split(X = df)):\n",
    "        df.loc[v_,'kfold'] = fold\n",
    "    df.to_csv('advertising_fold.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stratified K fold - Classification\n",
    "\n",
    "When we have skewed datasets, when we have binary classifications, \n",
    "*  90% positive sample  \n",
    "*  10 % negative sample\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Some classes have a lot of samples, and some don’t have that many. If we do a simple k-fold, we\n",
    "won’t have an equal distribution of targets in every fold. Thus, we choose stratified k-fold in this case.\n",
    "\n",
    "* The rule is simple. If it’s a standard classification problem, choose stratified k-fold blindly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import model_selection\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    df = pd.read_csv(#'advertising.csv')\n",
    "    df['kfold'] = -1\n",
    "    df = df.sample(frac = 1).reset_index(drop=True)\n",
    "    y = df.target.values\n",
    "    kf = model_selection.StratifiedKFold(n_splits=5)\n",
    "    for f,(t_,v_) in enumerate(kf.split(X =df, y = y)):\n",
    "        df.loc[v_, 'kfold'] = f\n",
    "    df.to_csv('#advertise_folds.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stratified Kfold - Regression - timeseries data\n",
    "\n",
    "We cannot use stratified k-fold directly, but there are ways to change the problem a bit so that we can use stratified k-fold for regression problems. Mostly, simple k-fold cross-validation works for any regression problem. However, if you see that the distribution of targets is not consistent, you can use stratified k-fold.\n",
    "\n",
    "* To use stratified k-fold for a regression problem, we have first to divide the target into bins, and then we can use stratified k-fold in the same way as for classification problems.\n",
    "\n",
    "* If you have a lot of samples( > 10k, > 100k), then you don’t need to care about the number of bins. Just divide the data into 10 or 20 bins.\n",
    "\n",
    "* If you do not have a lot of samples, you can use a simple rule like Sturge’s Rule to calculate the appropriate number of bins.\n",
    "\n",
    "bins = 1 + log2(N)\n",
    "\n",
    "N = len of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mds-student/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 216, got 192\n",
      "  return f(*args, **kwds)\n",
      "/home/mds-student/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:652: Warning: The least populated class in y has only 4 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn import model_selection\n",
    "\n",
    "def create_folds(data):\n",
    "    data['kfold'] = -1\n",
    "    data = data.sample(frac=1).reset_index(drop = True)\n",
    "    num_bins = np.floor(1+np.log2(len(data)))\n",
    "    data.loc[:,'bins'] = pd.cut(\n",
    "        data['target'],bins = num_bins, labels= False)\n",
    "    kf = model_selection.StratifiedKFold(n_splits=5)\n",
    "    for f,(t_,v_) in enumerate(kf.split(X = data, y = data.bins.values)):\n",
    "        data.loc[v_,'kfold'] = f\n",
    "    data = data.drop('bins', axis = 1)\n",
    "    return data\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    #creating a dataset, with 1500 samples and 100 features and 1 target\n",
    "    X, y = datasets.make_regression(n_samples = 15000, n_features = 100, n_targets = 1)\n",
    "    df = pd.DataFrame(X, columns= [f'f_{i}' for i in range(X.shape[1])])\n",
    "    df.loc[:,'target'] = y\n",
    "    df = create_folds(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f_0</th>\n",
       "      <th>f_1</th>\n",
       "      <th>f_2</th>\n",
       "      <th>f_3</th>\n",
       "      <th>f_4</th>\n",
       "      <th>f_5</th>\n",
       "      <th>f_6</th>\n",
       "      <th>f_7</th>\n",
       "      <th>f_8</th>\n",
       "      <th>f_9</th>\n",
       "      <th>...</th>\n",
       "      <th>f_92</th>\n",
       "      <th>f_93</th>\n",
       "      <th>f_94</th>\n",
       "      <th>f_95</th>\n",
       "      <th>f_96</th>\n",
       "      <th>f_97</th>\n",
       "      <th>f_98</th>\n",
       "      <th>f_99</th>\n",
       "      <th>target</th>\n",
       "      <th>kfold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.344447</td>\n",
       "      <td>-1.995182</td>\n",
       "      <td>-1.514464</td>\n",
       "      <td>0.245371</td>\n",
       "      <td>-1.265125</td>\n",
       "      <td>0.029895</td>\n",
       "      <td>-0.581069</td>\n",
       "      <td>-1.080737</td>\n",
       "      <td>-0.031236</td>\n",
       "      <td>-1.133373</td>\n",
       "      <td>...</td>\n",
       "      <td>0.144927</td>\n",
       "      <td>-0.768895</td>\n",
       "      <td>-0.731983</td>\n",
       "      <td>-0.925336</td>\n",
       "      <td>-0.203425</td>\n",
       "      <td>0.897261</td>\n",
       "      <td>-1.263357</td>\n",
       "      <td>-0.564291</td>\n",
       "      <td>20.425703</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.480440</td>\n",
       "      <td>-0.428910</td>\n",
       "      <td>0.345240</td>\n",
       "      <td>-1.039374</td>\n",
       "      <td>0.363398</td>\n",
       "      <td>-1.942665</td>\n",
       "      <td>0.169723</td>\n",
       "      <td>-0.929829</td>\n",
       "      <td>-0.564044</td>\n",
       "      <td>-0.824234</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.328204</td>\n",
       "      <td>-0.928913</td>\n",
       "      <td>-0.759538</td>\n",
       "      <td>0.132935</td>\n",
       "      <td>-0.288166</td>\n",
       "      <td>-2.238947</td>\n",
       "      <td>1.145854</td>\n",
       "      <td>0.121889</td>\n",
       "      <td>54.909779</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.510080</td>\n",
       "      <td>-1.308150</td>\n",
       "      <td>-0.824694</td>\n",
       "      <td>2.449228</td>\n",
       "      <td>0.542844</td>\n",
       "      <td>-1.945811</td>\n",
       "      <td>-0.458384</td>\n",
       "      <td>-1.496419</td>\n",
       "      <td>0.803799</td>\n",
       "      <td>-0.592972</td>\n",
       "      <td>...</td>\n",
       "      <td>0.618356</td>\n",
       "      <td>-0.498378</td>\n",
       "      <td>0.008155</td>\n",
       "      <td>0.074344</td>\n",
       "      <td>-0.252396</td>\n",
       "      <td>-0.890504</td>\n",
       "      <td>-1.085554</td>\n",
       "      <td>0.158722</td>\n",
       "      <td>126.928854</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.030511</td>\n",
       "      <td>-0.463971</td>\n",
       "      <td>-1.067302</td>\n",
       "      <td>2.280652</td>\n",
       "      <td>-0.176592</td>\n",
       "      <td>0.947312</td>\n",
       "      <td>-0.310826</td>\n",
       "      <td>1.960855</td>\n",
       "      <td>0.178239</td>\n",
       "      <td>1.125960</td>\n",
       "      <td>...</td>\n",
       "      <td>0.918040</td>\n",
       "      <td>-1.033999</td>\n",
       "      <td>0.731701</td>\n",
       "      <td>1.401393</td>\n",
       "      <td>0.101335</td>\n",
       "      <td>1.763901</td>\n",
       "      <td>0.799613</td>\n",
       "      <td>0.039592</td>\n",
       "      <td>408.295951</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.749481</td>\n",
       "      <td>-0.294192</td>\n",
       "      <td>0.194189</td>\n",
       "      <td>0.100953</td>\n",
       "      <td>1.148083</td>\n",
       "      <td>0.030195</td>\n",
       "      <td>2.620489</td>\n",
       "      <td>-0.149118</td>\n",
       "      <td>0.161522</td>\n",
       "      <td>0.536576</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024839</td>\n",
       "      <td>-0.500578</td>\n",
       "      <td>1.338352</td>\n",
       "      <td>0.424361</td>\n",
       "      <td>0.738802</td>\n",
       "      <td>0.557522</td>\n",
       "      <td>-0.616515</td>\n",
       "      <td>0.088568</td>\n",
       "      <td>603.676395</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 102 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        f_0       f_1       f_2       f_3       f_4       f_5       f_6  \\\n",
       "0  0.344447 -1.995182 -1.514464  0.245371 -1.265125  0.029895 -0.581069   \n",
       "1 -0.480440 -0.428910  0.345240 -1.039374  0.363398 -1.942665  0.169723   \n",
       "2 -0.510080 -1.308150 -0.824694  2.449228  0.542844 -1.945811 -0.458384   \n",
       "3 -0.030511 -0.463971 -1.067302  2.280652 -0.176592  0.947312 -0.310826   \n",
       "4  1.749481 -0.294192  0.194189  0.100953  1.148083  0.030195  2.620489   \n",
       "\n",
       "        f_7       f_8       f_9  ...        f_92      f_93      f_94  \\\n",
       "0 -1.080737 -0.031236 -1.133373  ...    0.144927 -0.768895 -0.731983   \n",
       "1 -0.929829 -0.564044 -0.824234  ...   -0.328204 -0.928913 -0.759538   \n",
       "2 -1.496419  0.803799 -0.592972  ...    0.618356 -0.498378  0.008155   \n",
       "3  1.960855  0.178239  1.125960  ...    0.918040 -1.033999  0.731701   \n",
       "4 -0.149118  0.161522  0.536576  ...    0.024839 -0.500578  1.338352   \n",
       "\n",
       "       f_95      f_96      f_97      f_98      f_99      target  kfold  \n",
       "0 -0.925336 -0.203425  0.897261 -1.263357 -0.564291   20.425703      0  \n",
       "1  0.132935 -0.288166 -2.238947  1.145854  0.121889   54.909779      0  \n",
       "2  0.074344 -0.252396 -0.890504 -1.085554  0.158722  126.928854      0  \n",
       "3  1.401393  0.101335  1.763901  0.799613  0.039592  408.295951      0  \n",
       "4  0.424361  0.738802  0.557522 -0.616515  0.088568  603.676395      0  \n",
       "\n",
       "[5 rows x 102 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train test split of sklearn\n",
    "\n",
    "Go for it when you don't have much time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
